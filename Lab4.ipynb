{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCj-5DLhu-ya"
      },
      "outputs": [],
      "source": [
        "# Task 1:\n",
        "#Q:\n",
        "# Are we dealing with supervised or unsupervised learning?\n",
        "#A: we are dealing with supervised learning since 2 specific class in which we trained our data to\n",
        "\n",
        "#Codes:\n",
        "#Defining the input data to train the model\n",
        "\n",
        "x_train=[\"This was awesome an awesome movie\", \n",
        "         \"Great movie! I liked it a lot\", \n",
        "         \"Happy ending! awesome acting by the hero\",\n",
        "         \"loved it truly great\",\n",
        "        \"bad not up to the mark\",\n",
        "         \"could have been better\",\n",
        "         \"surely a disappointing movie\"\n",
        "        ]\n",
        "#1 for positive, 0 for negative\n",
        "y_train=[1,1,1,1,0,0,0]\n",
        "\n",
        "#to test our trained data\n",
        "x_test=[\"I was happy and happy, I loved the acting in the movie\", \n",
        "        \"The movie I saw is bad\", \"I don't know if I like it or not, Its okay\", \"the movie is mysterious and exciting\", \"I don't like it at all\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 2:\n",
        "# Do the necessary imports and instantiations:\n",
        "\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "import nltk\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "\n",
        "# # In case of import errors\n",
        "! pip install nltk\n",
        "! pip install textblob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "tokenizer=RegexpTokenizer(r'\\w+')\n",
        "en_stopwords=set(stopwords.words('english'))\n",
        "ps=PorterStemmer()\n",
        "\n",
        "\n",
        "#Q: What is a token for us?\n",
        "#A: our token is a word\n",
        "\n",
        "\n",
        "# Task 3:\n",
        "# Define a function that cleans our text:\n",
        "\n",
        "stop_words = stopwords.words(\"english\")\n",
        "wordnet = WordNetLemmatizer()\n",
        "def clean_text(i):\n",
        "  outl = []\n",
        "  for x in i:\n",
        "    x = x.lower()\n",
        "    x = ' '.join([word for word in x.split(' ') if word not in stop_words])\n",
        "    x = x.encode('ascii', 'ignore').decode()\n",
        "    x = re.sub(r'https*\\S+', ' ', x)\n",
        "    x = re.sub(r'@\\S+', ' ', x)\n",
        "    x = re.sub(r'#\\S+', ' ', x)\n",
        "    x = re.sub(r'\\'\\w+', '', x)\n",
        "    x = re.sub('[%s]' % re.escape(string.punctuation), ' ', x)\n",
        "    x = re.sub(r'\\w*\\d+\\w*', '', x)\n",
        "    x = re.sub(r'\\s{2,}', ' ', x)\n",
        "    outl.append(x)\n",
        "  return outl\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZ3ykwZ4vnWf",
        "outputId": "d5e19f01-bde6-4d0e-c242-14b845fb1d06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.7/dist-packages (0.15.3)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.7/dist-packages (from textblob) (3.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (2022.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (4.64.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7hKYSjGo8Lf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 4:\n",
        "# Call your function cleanText to clean x_train and x_test. Name them x_clean and xt_clean.\n",
        "x_clean = clean_text(x_train) \n",
        "xt_clean = clean_text(x_test) \n",
        "\n",
        "\n",
        "print(x_clean)\n",
        "print(xt_clean)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3KdG6X0vt4Y",
        "outputId": "1e79f004-eefa-4880-cba4-bb032606cc6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['awesome awesome movie', 'great movie liked lot', 'happy ending awesome acting hero', 'loved truly great', 'bad mark', 'could better', 'surely disappointing movie']\n",
            "['happy happy loved acting movie', 'movie saw bad', 'know like not okay', 'movie mysterious exciting', 'like']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 5:\n",
        "# The goal of this task is to vectorize your text.\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cv=CountVectorizer(ngram_range=(1,2))\n",
        "\n",
        "x_vec=cv.fit_transform(x_clean).toarray()\n",
        "\n",
        "x_vec\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVWC1y_u4b_P",
        "outputId": "c361cbef-87c8-47b5-d59d-2997df2f2dc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 2, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "        1, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
              "       [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "        0, 1, 1, 0, 0, 0, 0, 0, 1, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 1, 0, 1, 1, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 6:\n",
        "# Add the following piece of code and try to understand the vectorization\n",
        "\n",
        "cv.get_feature_names()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAOGB32sU6GC",
        "outputId": "35804b07-da9f-40f4-c82f-5399bfbc0d12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['acting',\n",
              " 'acting hero',\n",
              " 'awesome',\n",
              " 'awesome acting',\n",
              " 'awesome awesome',\n",
              " 'awesome movie',\n",
              " 'bad',\n",
              " 'bad mark',\n",
              " 'better',\n",
              " 'could',\n",
              " 'could better',\n",
              " 'disappointing',\n",
              " 'disappointing movie',\n",
              " 'ending',\n",
              " 'ending awesome',\n",
              " 'great',\n",
              " 'great movie',\n",
              " 'happy',\n",
              " 'happy ending',\n",
              " 'hero',\n",
              " 'liked',\n",
              " 'liked lot',\n",
              " 'lot',\n",
              " 'loved',\n",
              " 'loved truly',\n",
              " 'mark',\n",
              " 'movie',\n",
              " 'movie liked',\n",
              " 'surely',\n",
              " 'surely disappointing',\n",
              " 'truly',\n",
              " 'truly great']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 7:\n",
        "# Similarly, transform xt_clean\n",
        "\n",
        "xt_vec=cv.transform(xt_clean).toarray()"
      ],
      "metadata": {
        "id": "T2B83a1SVGPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 8:\n",
        "#Import the naive bayes classifier and use it:\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "#this version of naive bayes is used for text classification\n",
        "\n",
        "mn=MultinomialNB()\n",
        "\n",
        "mn.fit(x_vec,y_train)\n",
        "\n",
        "y_pred=mn.predict(xt_vec)\n"
      ],
      "metadata": {
        "id": "UPgmti58VRuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Print out y_pred and try to understand its meaning\n",
        "print(y_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wI3ESF3GVa68",
        "outputId": "694642f3-a014-4a6e-9f25-52a72c2136ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 1 1 1]\n"
          ]
        }
      ]
    }
  ]
}